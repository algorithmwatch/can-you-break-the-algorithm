"explainers": {
    "ECAT": {
      "title@en": "Subject: The European Center for Algorithmic Transparency",
      "title@de": "Betreff: Das Europäische Zentrum für algorithmische Transparenz",
      "body@en": "<p>Hello colleague,</p><p>As I told you, here's a short helper about ECAT.</p><p>ECAT opened in April 2023 in Sevilla, Spain. It should grow to 30 people by 2024. They shall support European regulators in their investigations of automated systems.</p><p>AlgorithmWatch wrote an explainer about it: <a target='_blank' href='https://algorithmwatch.org/en/dsa-explained/'>https://algorithmwatch.org/en/dsa-explained/</a>.</p><p>Cheers,</p><p>Lisbet</p>",
      "body@de": "<p>Hallo,</p><p>wie angekündigt hier ein paar erklärende Worte zum Europäischen Zentrum für algorithmische Transparenz.</p><p>Es wurde im April 2023 in Sevilla eröffnet. Bis 2024 soll es 30 Mitarbeiter*innen haben. Es soll die europäischen Aufsichtbehörden dabei unterstützen, automatisierte Systeme zu untersuchen.</p><p>AlgorithmWatch hat einen Explainer dazu veröffentlicht: <a target='_blank' href='https://algorithmwatch.org/en/dsa-explained/'>https://algorithmwatch.org/de/dsa-erklaert//</a>.</p><p>Grüße</p><p>Lisbet</p>"
    },
    "revolvingDoor": {
      "title@en": "Subject: Revolving doors",
      "title@de": "Betreff: Windmaschinen",
      "body@en": "<p>Hi there,</p><p>Large tech companies have a thing European journalists don't: money. They hired lots of former journalists to carry out their lobbying. They will sweet-talk you into believing everything they say.</p><p>Stay alert, and don't fall for their tricks. Every piece of information you get from them must be verified, or at least veryfiable. Pay attention when they use the conditional tense, or say that their algorithm <i>might</i>, or <i>may</i>, or <i>could</i> do a certain thing. We need certainty.</p><p>Cheers,</p><p>Lisbet</p>",
      "body@de": "<p>Hallo,</p><p>die großen Tech-Konzerne haben Journalist*innen gegenüber einen Vorteil: Sie haben Geld. Deshalb können sie es sich leisten, viele frühere Journalist*innen dafür zu bezahlen, die Lobbyarbeit für sie zu erledigen und jede Lüge sehr überzeugend klingen zu lassen.</p><p>Da ist Vorsicht geboten, fall nicht auf ihre Tricks rein. Alle Informationen, die du von ihnen bekommst, müssen überprüft werden und überprüfbar sein. Achte darauf, ob sie das Konditional verwenden oder sagen, dass der Algorithmus etwas tun <i>könnte</i> oder <i>würde</i>. Uns interessieren nur Fakten.</p><p>Grüße</p><p>Lisbet</p>"
    },
    "AlgorithmicImaginaries": {
      "title@en": "Subject: Algorithmic imaginaries",
      "title@de": "Betreff: Welche Vorstellungen wir mit Algorithmen verbinden",
      "body@en": "<p>Hi colleague,</p><p>People who use or are subjected to automated systems don't have access to the black boxes anymore than you do. But they have plenty of experience.</p><p>Sometimes, they do manage to pull out actions based on it, like when TikTokers managed to <a href='https://archive.is/SsGxu' target='_blank'>sink a far-right event in 2020</a> by fake-registering then not showing up.</p><p>But most of the time, this hands-on knowledge is fleeting. One YouTuber thought he'd cracked the TikTok algorithm, for instance, only to later realize that <a href='https://r.algorithmwatch.org/nl3/12S3npamH6ovXuqgdZQczg' target='_blank'>he had not</a>.</p><p>This is what academics call <b>algorithmic imaginaries</b>: What people think about an automated system. Even if the beliefs of users are not based in fact, these beliefs exist and must be taken into account in your reporting.</p><p>Cheers,</p><p>Lisbet</p>",
      "body@de": "<p>Hi,</p><p>Menschen, die automatisierten Systemen ausgesetzt sind oder sie verwenden, haben auch keinen besseren Einblick in sie als du. Was sie aber haben ist Erfahrung damit.</p><p>Manchmal gelingt es ihnen, sie für ihre Zwecke zu benutzen. TikTok-User*innen haben zum Beispiel <a href='https://archive.is/SsGxu' target='_blank'>2020 eine rechtsradikale Veranstaltung damit sabotiert</a>, indem sie sich erst massenhaft dafür angemeldet haben und dann nicht aufgetaucht sind.</p><p>So ein praktisches Know-how ist aber meistens schnell veraltet. Ein YouTuber dachte mal, er hätte den TikTok-Algorithmus geknackt, bis ihm aufging, dass <a href='https://r.algorithmwatch.org/nl3/12S3npamH6ovXuqgdZQczg' target='_blank'>das Quatsch war</a>.</p><p>Wissenschaftler*innen sprechen hier von <b>Imaginationen, die Algorithmen in uns wachrufen</b>, also welche Vorstellungen sie mit automatisierten Systemen verbinden. Selbst wenn diese Vorstellungen nicht den Tatsachen entsprechen, führen sie ein Eigenleben. Deswegen solltest du bei deiner Recherche daran denken und sie ernst nehmen.</p><p>Grüße</p><p>Lisbet</p>"
    },
    "Sources": {
      "title@en": "Subject: Double-check your sources",
      "title@de": "Betreff: Immer mindestens zwei Quellen",
      "body@en": "<p>Hi colleague,</p><p>In this trade, you cannot blindly trust people.</p><p>Whenever a person shares a fact with you, you need to double-check it, by asking someone or finding a document that confirms the initial statement.</p><p>The risk of being lied to is not hypothetical. In October 2022, <i>The Wire</i> published an explosive revelation about Meta... based on fake screenshots. <a href='https://www.theverge.com/2022/10/26/23425377/the-wire-subject-deception-member-team-meta-india' target='_blank'>They had to retract the story</a>.</p><p>Cheers,</p><p>Lisbet</p>",
      "body@de": "<p>Hi,</p><p>in unserer Branche sollten wir niemandem trauen.</p><p>Alle Informationen müssen von mindestens einer zweiten Quelle bestätigt worden sein, sei es von einer zweiten Person oder einem Dokument.</p><p>Wir werden oft angelogen. Im Oktober 2022 brachte <i>The Wire</i> eine explosive Enthüllungsstory über Meta. Leider haben sich die darin als Beweise angeführten Screenshots als gefälscht entpuppt. <a href='https://www.theverge.com/2022/10/26/23425377/the-wire-subject-deception-member-team-meta-india' target='_blank'>The Wire musste die Story deswegen zurückziehen </a>.</p><p>Grüße</p><p>Lisbet</p>"
    },
    "AlgorithmicAudits": {
      "title@en": "Subject: Auditing an automated system",
      "title@de": "Betreff: Wie ein automatisiertes System geprüft wird",
      "body@en": "<p>Dear journalist,</p><p>I enjoyed talking to you earlier.</p><p>Auding an automated system is actually much more than running computer code. You need to understand how the system works in relation with the people who operate it, and the people who use it.</p><p>Academics call these kinds of investigation \"mixed-methods\", which are a combination of qualitative and quantitative techniques.</p><p>AlgorithmWatch wrote a good piece on the topic: <a href='https://algorithmwatch.org/en/researchers-audit-recommender-systems/' target='_blank'>How researchers are upping their game to audit recommender systems</a>.</p><p>Good luck with your investigation,</p><p>Dr. Brandt</p>",
      "body@de": "<p>Liebe*r Pressevertreter*in,</p><p>es hat mich gefreut, vorhin mit Ihnen zu reden.</p><p>Es gehört mehr dazu, ein automatisiertes System zu prüfen, als nur einen Computercode auszuführen. Sie müssen lernen zu verstehen, wie das System funktioniert – für die Menschen, die es betreiben, und die Menschen, die es verwenden.</p><p>Diese Art der Untersuchung nennen Wissenschaftler*innen „Mixed Methods”, was eine Kombination aus qualitativen und quantitativen Methoden bezeichnet.</p><p>AlgorithmWatch hat dazu einen guten Artikel veröffentlicht: <a href='https://algorithmwatch.org/en/researchers-audit-recommender-systems/' target='_blank'>How researchers are upping their game to audit recommender systems</a>.</p><p>Viel Glück bei Ihrer Recherche!</p><p>Dr. Brandt</p>"
    }
  }
}
